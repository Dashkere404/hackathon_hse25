{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqNuouv-SWoI"
      },
      "source": [
        "### Все импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_s8Ekpi3o97"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install transformers datasets accelerate rouge-score nltk bitsandbytes peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhQgCGRqSVwc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge import Rouge\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g9kTa_NRicD"
      },
      "source": [
        "### Загрузка данных для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6TKBPEtRNk6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLy7dN7Rwve"
      },
      "source": [
        "### Код для загрузки различных моделей (можете использовать любые, но не берите слишком тяжеловесные, на бесплатных гпу с колаба вы не успеете ее обучить :)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC-vZYpU4CF0"
      },
      "source": [
        "### Класс для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzzuOeV8SCtT"
      },
      "outputs": [],
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(self, model_name: str, task: str = \"causal\", quantization: bool = True):\n",
        "        self.model_name = model_name\n",
        "        self.task = task\n",
        "        self.quantization = quantization\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model, self.tokenizer = self.load_model()\n",
        "\n",
        "    def load_model(self):\n",
        "        kwargs = {\"load_in_4bit\": True, \"device_map\": \"auto\"} if self.quantization else {\"device_map\": \"auto\"}\n",
        "\n",
        "        if self.task == \"causal\":\n",
        "            model = AutoModelForCausalLM.from_pretrained(self.model_name, **kwargs)\n",
        "        elif self.task == \"classification\":\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(self.model_name, **kwargs)\n",
        "        else:\n",
        "            raise ValueError(\"Неподдерживаемая задача\")\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        model.to(self.device)\n",
        "        return model, tokenizer\n",
        "\n",
        "    def load_data(self, data_path: str):\n",
        "        dataset = load_dataset(\"json\", data_files=data_path)\n",
        "        return dataset.map(lambda examples: self.tokenizer(examples[\"question\"] + \" \" + examples.get(\"context\", \"\"),\n",
        "                                                      truncation=True, padding=\"max_length\", max_length=512),\n",
        "                                                      batched=True)\n",
        "\n",
        "    def train(self, train_data_path: str, output_dir: str = \"./results\", epochs: int = 3, batch_size: int = 2):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        tokenized_datasets = self.load_data(train_data_path)\n",
        "        train_dataloader = torch.utils.data.DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.model.train()\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=5e-5)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "\n",
        "            for batch in progress_bar:\n",
        "                batch = {k: v.to(self.model.device) for k, v in batch.items()}\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(**batch)\n",
        "                loss = outputs.loss\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        self.model.save_pretrained(output_dir)\n",
        "        print(f\"Модель {self.model_name} сохранена в {output_dir}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts2-P1yX36z8"
      },
      "source": [
        "### Обучаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwzKcN543_BI"
      },
      "outputs": [],
      "source": [
        "available_models = {\n",
        "    \"causal\": [\"ai-forever/saiga_mistral_7b\", \"mistralai/Mistral-7B-Instruct\", \"SberbankAI/FRED-T5-1.7B\"],\n",
        "    \"classification\": [\"distilbert-base-uncased\", \"bert-tiny\"]\n",
        "} #гуглите любые, это просто примерус\n",
        "\n",
        "selected_model = \"ai-forever/saiga_mistral_7b\"\n",
        "trainer = ModelTrainer(selected_model)\n",
        "trainer.train(\"train_data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egz3ldjcSGjU"
      },
      "source": [
        "### Код для подсчета метрик вашей модельки :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from metrics import Validator #metrics.py\n",
        "\n",
        "validator = Validator()\n",
        "\n",
        "res = validator.validate_dataset(df, use_ragas=True) #df: пандас датасет с нужными полями: answer, ground_truth, context, question\n",
        "\n",
        "# contex_rec = res[\"context_recall\"]\n",
        "# contex_prec = res[\"context_precision\"]\n",
        "# answer_cor_lit = res[\"answer_correctness_literal\"]\n",
        "# answer_cor_neu = res[\"answer_correctness_neural\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Графички, шоб красиво :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metric_distribution(results: dict):\n",
        "    \"\"\"Построить распределение каждой метрики.\"\"\"\n",
        "    plt.figure(figsize=(18, 12))\n",
        "    for i, (metric, values) in enumerate(results.items(), 1):\n",
        "        plt.subplot(2, 2, i)\n",
        "        sns.histplot(values, bins=20, kde=True, color=\"skyblue\")\n",
        "        plt.title(f\"Распределение {metric}\")\n",
        "        plt.xlabel(\"Оценка\")\n",
        "        plt.ylabel(\"Частота\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_average_scores(results: dict):\n",
        "    \"\"\"Построить среднее значение для каждой метрики.\"\"\"\n",
        "    avg_scores = {metric: sum(values) / len(values) if values else 0.0 for metric, values in results.items()}\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=list(avg_scores.keys()), y=list(avg_scores.values()), palette=\"viridis\")\n",
        "    plt.title(\"Средние значения для каждой метрики\")\n",
        "    plt.xlabel(\"Метрика\")\n",
        "    plt.ylabel(\"Средняя оценка\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def plot_metrics_comparison(results: dict):\n",
        "    \"\"\"Построить сравнение метрик по образцам.\"\"\"\n",
        "    df = pd.DataFrame(results)\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    sns.boxplot(data=df, palette=\"Set2\")\n",
        "    plt.title(\"Сравнение метрик (ящиковая диаграмма)\")\n",
        "    plt.xlabel(\"Метрика\")\n",
        "    plt.ylabel(\"Оценка\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def plot_correlation_heatmap(results: dict):\n",
        "    \"\"\"Построить тепловую карту корреляции между метриками.\"\"\"\n",
        "    df = pd.DataFrame(results)\n",
        "    correlation = df.corr()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(\"Тепловая карта корреляции метрик\")\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
